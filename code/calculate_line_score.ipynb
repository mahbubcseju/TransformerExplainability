{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "from transformers import  RobertaTokenizer\n",
    "\n",
    "from config import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained('microsoft/codebert-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_jsonl(path):\n",
    "    f = open(path, 'r')\n",
    "    data_ = f.read().split(\"\\n\")\n",
    "    f.close()\n",
    "\n",
    "    return [json.loads(sample) for sample in data_]\n",
    "arg = Arg()\n",
    "data = read_jsonl(arg.test_data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_lines_to_tokens(line, tokenizer):\n",
    "\n",
    "    code_tokens=tokenizer.tokenize(code)\n",
    "    source_tokens =[tokenizer.cls_token]+code_tokens+[tokenizer.sep_token]\n",
    "    source_ids =  tokenizer.convert_tokens_to_ids(source_tokens)\n",
    "    padding_length = args.block_size - len(source_ids)\n",
    "    source_ids+=[tokenizer.pad_token_id]*padding_length\n",
    "    return InputFeatures(source_tokens, source_ids, js[args.idx_key], js['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_explanation_output(path):\n",
    "    f = open(path, 'r')\n",
    "    data_ = json.loads(f.read())\n",
    "    f.close()\n",
    "    return data_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanations = read_explanation_output('output.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "line_scores = []\n",
    "for explan, sample in zip(explanations, data):\n",
    "    assert(int(explan['idx']) == int(sample['id']))\n",
    "    func = sample['func']\n",
    "    tokens = explan['tokens'][0]\n",
    "    scores = explan['scores'][0]\n",
    "    index = tokens.index(\"</s>\")\n",
    "    tokens = tokens[1:index]\n",
    "    scores = scores[1:index]\n",
    "\n",
    "    no = 0\n",
    "    line_score = []\n",
    "    for line in func.split(\"\\n\"):\n",
    "        line_ = ' '.join(line.split())\n",
    "        if line_ == '' or line_ == '\\n' or tokens == []:\n",
    "            line_score.append(0)\n",
    "            continue\n",
    "        if no:\n",
    "            line_ = ' ' + line_\n",
    "        no += 1\n",
    "\n",
    "        line_token = tokenizer.tokenize(line_)\n",
    "        \n",
    "        end_ind = min(len(line_token), len(tokens))\n",
    "        assert tokens[: end_ind] == line_token[:end_ind], tokens[:end_ind]\n",
    "\n",
    "        score_ = scores[:end_ind]\n",
    "        line_score.append(sum(score_) / len(score_))\n",
    "\n",
    "        tokens = tokens[end_ind:]\n",
    "        scores = scores[end_ind:]\n",
    "    \n",
    "    line_scores.append(line_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10  0.6566473988439306\n",
      "False Alarm  8.256647398843926\n"
     ]
    }
   ],
   "source": [
    "top_10, false_alarm = 0, 0\n",
    "total_vul = 0\n",
    "for sample, line_score in zip(data, line_scores):\n",
    "    if sample['target'] == 0:\n",
    "        continue\n",
    "    total_vul += 1\n",
    "    func = sample['func'].split(\"\\n\")\n",
    "    diff = sample['diff']\n",
    "    assert len(func) == len(line_score)\n",
    "    indices = []\n",
    "    for key in diff:\n",
    "        ind = int(key)\n",
    "        assert func[ind] == diff[key]\n",
    "        indices.append(ind)\n",
    "    \n",
    "    ind_score = [(score, ind) for ind, score in enumerate(line_score)]\n",
    "    ind_score = sorted(ind_score, reverse=True)\n",
    "\n",
    "    # print(indices)\n",
    "    for idx, (score, ind) in enumerate(ind_score):\n",
    "        # print(ind)\n",
    "        if ind in indices:\n",
    "            \n",
    "            cnt = idx\n",
    "            for k in range(idx):\n",
    "                if func[k] == '' or func[k] == ' ' or func[k] == '\\n':\n",
    "                    cnt -= 1\n",
    "            \n",
    "            false_alarm += cnt / 3\n",
    "            if cnt < 12:\n",
    "                top_10 += 1\n",
    "\n",
    "         \n",
    "                # print(sample['id'])\n",
    "            break\n",
    "            \n",
    "print('Top 10 ', top_10 / total_vul)\n",
    "print('False Alarm ', false_alarm / total_vul)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "665A",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "76c1c3abec198d3a28acb00577a50bb14399c9cd08b83d8d0bc9d05da6e733fc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
